- Code Availability: https://github.com/abidlabs/contrastive
  Description: "A modified version of PCA, where the covariance matrix (COV) is the\
    \ difference between COV(case/target) and \u03B1COV(control/background). The hyperparameter\
    \ \u03B1 is used to balance having a high case variance and a low control variance.\
    \ To provide some intuition, when \u03B1 is 0, the model reduces to classic PCA\
    \ on the case data.  Optimal alphas (equal to k clusters) are identified using\
    \ spectral clustering over a range of cPCA runs with different alphas, with selection\
    \ based on the similarity of cPCA outputs."
  Inspired by:
  - PCA
  - Contrastive Mixture Models (Zou et al., 2013)
  Method: cPCA
  Model:
  - Modified PCA
  Publication: https://www.nature.com/articles/s41467-018-04608-8#Sec7
  Published: true
  Task: '[''Linear Gene Programmes'', ''Contrastive Disentanglement'']'
  Year: 2018
- Code Availability: https://www.zhanglab-amss.org/homepage/software.html
  Description: "A non-negative matrix factorisation that decomposes gene expression\
    \ matrices into common and specific patterns. For each condition, the observed\
    \ expression matrix is approximated as the sum of a common component - represented\
    \ by a common feature matrix (Wc) with condition-specific coefficient matrices\
    \ (Hc\u2081, Hc\u2082) - and a specific component unique to each condition, represented\
    \ by its own feature matrix (Ws\u1D62) and coefficients (Hs\u1D62). The model\
    \ uses an alternating approach to minimize the combined reconstruction error (squared\
    \ Frobenius norm) across common and shared components."
  Inspired by:
  - iNMF
  - NMF
  Method: CSMF
  Model:
  - NMF
  Publication: https://academic.oup.com/nar/article/47/13/6606/5512984
  Published: true
  Task: '[''Linear Gene Programmes'', ''Contrastive Disentanglement'']'
  Year: 2019
- Code Availability: https://github.com/kseverso/contrastive-LVM
  Description: 'A family of contrastive latent variable models (cLVMs), where case
    data are modeled as the sum of background and salient latent embeddings, while
    control data are reconstructed solely from background embeddings: - cLVM with
    Gaussian likelihoods and priors - Sparse cLVM with horseshoe prior used to regularize
    the weights - Robust cLVM with a Student''s t distribution - cLVM with automatic
    relevance determination (ARD) to regularize (select) the columns of the weight
    matrix - contrastive VAE, as a non-linear extension of the framework The shared
    concept across these models is that each model learns a shared set of latent variables
    for the background and target data, while salient latent variables are learnt
    solely for the target data.'
  Inspired by:
  - Contrastive PCA
  Method: cLVM
  Model:
  - Factor Models
  - Contastive VAE
  Publication: https://arxiv.org/abs/1811.06094
  Published: true
  Task: '[''Linear Gene Programmes'', ''Contrastive Disentanglement'']'
  Year: 2019
- Code Availability: https://github.com/abidlabs/contrastive_vae
  Description: 'VAE with two sets of latent variables (two encoders): salient and
    background, each learned using amortised inference from both case and control
    observations, respectively. The latent variables are concatenated and then decoded
    simultaneously via a shared decoder. During the generative process (decoding),
    the control observations are reconstructed solely from the background latent space,
    with salient latent variables being set to 0, while the case observations are
    generated from both sets of latent variables. Optionally, the two sets of latent
    variables can be further disentagled by minimizing their total correlation, in
    practice done by training a discriminator to distinguish real from permuted latent
    samples.'
  Inspired by:
  - Contrastive PCA
  Method: cVAE
  Model:
  - Contrastive VAE
  Publication: https://arxiv.org/pdf/1902.04601
  Published: false
  Task: '[''Contrastive Disentanglement'']'
  Year: 2019
- Code Availability: https://github.com/PhilBoileau/EHDBDscPCA
  Description: "A sparse version of contrastive PCA that enhances interpretability\
    \ in high-dimensional settings by integrating \u21131regularization into an iterative\
    \ procedure to estimate sparse loadings and principal components"
  Inspired by:
  - Contrastive PCA
  - Probabilistic PCA
  Method: scPCA
  Model:
  - Modified PCA
  Publication: https://academic.oup.com/bioinformatics/article/36/11/3422/5807607
  Published: true
  Task: '[''Linear Gene Programmes'', ''Contrastive Disentanglement'']'
  Year: 2020
- Code Availability: https://github.com/welch-lab/MichiGAN
  Description: "MichiGAN is a two-step approach that first uses a \u03B2-TCVAE - a\
    \ variant of the variational autoencoder that penalizes total correlation among\
    \ latent variables to promote disentangled representations. These latent representations\
    \ (posterior means or samples) are then used to condition a Wasserstein GAN, the\
    \ generator of which similarly to the VAE reconstructs the data from the latent\
    \ variables, while attempting to 'fool' a discriminator whether the samples were\
    \ real or generated. Counterfactual predictions are done via latent space arithmetics\
    \ as in scGEN."
  Inspired by:
  - scGEN
  - InfoGAN
  Method: MichiGAN
  Model:
  - VAE
  - conditioned GAN
  Publication: https://link.springer.com/article/10.1186/s13059-021-02373-4
  Published: true
  Task: '[''Unsupervised Disentanglement'', ''Seen Perturbation Prediction'', ''Combinatorial
    Effect Prediction'']'
  Year: 2021
- Code Availability: https://github.com/andrewcharlesjones/pcpca
  Description: "A probabilistic model that builds on cPCA, additionally proposing\
    \ a case-control-ratio-adjusted \u03B1 as a more interpretable alternative to\
    \ the same parameter in cPCA (see comment above)."
  Inspired by: .nan
  Method: PCPCA
  Model:
  - modified PCA
  Publication: https://projecteuclid.org/journals/annals-of-applied-statistics/volume-18/issue-3/Probabilistic-contrastive-dimension-reduction-for-case-control-study-data/10.1214/24-AOAS1877.short
  Published: true
  Task: '[''Linear Gene Programmes'', ''Contrastive Disentanglement'']'
  Year: 2024
- Code Availability: https://github.com/andrewcharlesjones/cplvm
  Description: 'A family of contrastive Poisson latent variable models (CPLVMs), based
    on a Gamma-Poisson hierarchical generative process: - CPLVM: The variational posterior
    is approximated using log-normal distributions, preserving non-negativity in the
    latent factors. - CGLVM: Extends CPLVM by allowing latent factors to take negative
    values, replacing Gamma priors with Gaussian priors and using a log-link function
    for the Poisson rates. Variational posteriors are modeled as multivariate Gaussians.
    The authors also propose a hypothesis testing framework, in which log-(ELBO)-Bayes
    is calculated between a Null model, omitting the salient latent space, and the
    full contrastive model. This framework is used to quantify global (across all
    genes) and joint expression changes in subsets of genes (akin to gene set enrichment
    analysis).'
  Inspired by:
  - cPCA
  - cLVMs
  - scVI (hypothesis testing)
  Method: CPLVMs
  Model:
  - NB likelihood
  - Factor Models
  Publication: https://projecteuclid.org/journals/annals-of-applied-statistics/volume-16/issue-3/Contrastive-latent-variable-modeling-with-application-to-case-control-sequencing/10.1214/21-AOAS1534.short
  Published: true
  Task: '[''Linear Gene Programmes'', ''Contrastive Disentanglement'']'
  Year: 2022
- Code Availability: https://github.com/gemoran/sparse-vae-code
  Description: Spike and Slab Lasso applied to (non-linear) decoder weights. They
    show poofs of identifiability when at least 2 "anchor features" are present.
  Inspired by:
  - oi-VAE
  - VSC
  - beta-VAE
  Method: sparseVAE
  Model:
  - VAE
  Publication: https://arxiv.org/pdf/2110.10804
  Published: true
  Task: '[''Unsupervised Disentanglement'']'
  Year: 2022
- Code Availability: https://github.com/scverse/scvi-tools/tree/main/src/scvi/external/contrastivevi
  Description: 'The successor to mmVAE introducing improvements: counts are modeled
    using a negative binomial distribution, and the MMD loss is replaced with the
    Wasserstein distance. More specifically, the Wasserstein distance is computed
    exclusively for the salient latent variables of the control data, ensuring it
    approaches zero. The Wasserstein penalty is optional and is set to 0 (no penalty)
    by default'
  Inspired by:
  - scVI / totalVI
  - cVAE
  - Conditional VAE
  - mmVAE (theirs)
  Method: ContrastiveVI
  Model:
  - ZINB Likelihood
  - Protein-Count (totalVI) Likelihood
  - Contrastive VAE
  - Multi-modal
  Publication: https://www.nature.com/articles/s41592-023-01955-3
  Published: true
  Task: '[''Non-linear Gene Programmess'', ''Contrastive Disentanglement'']'
  Year: 2023
- Code Availability: https://github.com/suinleelab/MM-cVAE
  Description: A Contrastive VAE framework, similar to cVAE, which additionally incorporates
    a maximum mean discrepancy (MMD) loss to enforce salient latent variables in the
    control data to approach zero, while also using it to align the background latent
    variables between case and control conditions.
  Inspired by: .nan
  Method: mmVAE
  Model:
  - Contrastive VAE
  Publication: https://arxiv.org/pdf/2202.10560
  Published: true
  Task: '[''Contrastive Disentanglement'']'
  Year: 2022
- Code Availability: https://github.com/Genentech/multiGroupVI
  Description: An extension of ContrastiveVI to multi-case (multi-group) disentaglement
    via multiple group-specific salient encoders.
  Inspired by:
  - ContrastiveVI (theirs)
  Method: MultiGroupVI
  Model:
  - ZINB Likelihood
  - VAE
  - Contrastive
  Publication: https://proceedings.mlr.press/v200/weinberger22a
  Published: true
  Task: '[''Non-linear Gene Programmess'', ''Contrastive Disentanglement'']'
  Year: 2022
- Code Availability: https://github.com/theislab/inVAE
  Description: 'VAE model, which incorporates technical and biological covariates
    into two sets of latent variables:  - Z_I embeds biologically-relevant variables
    - Z_B embeds the unwanted variability in the data (i.e. batch effect labels) These
    are then fed into a shared encoder, along with the count data. The output of this
    shared encoder is fed to the decoder. Optionally, further disentanglement of the
    two latent variable sets is achieved by minimizing their total correlation, which
    is approximated via a minibatch-weighted estimator that quantifies the difference
    between the joint posterior and the product of individual marginal distributions.'
  Inspired by:
  - scVI
  - iVAE
  - "\u03B2-TCVAE"
  Method: inVAE
  Model:
  - VAE
  - NB Likelihood
  Publication: https://www.biorxiv.org/content/10.1101/2024.12.06.627196v1.full
  Published: false
  Task: '[''Multi-component Disentanglement'', ''Non-linear Gene Programmess'']'
  Year: 2024
- Code Availability: '-'
  Description: 'A VAE that disentangles disease (case) from healthy (control) cells
    by learning invariant background and salient space representations. The background
    and salient representations are summed to reconstruct the count data, with an
    (optional) interaction term capturing the interplay between cell type and disease.
    As done in contrastive methods, the salient representation for control cells is
    set to 0 during the generative (data reconstruction) process. The invariance of
    the background latent variables is enforced through two GAN-style neural networks:
    one encouraging the prediction of cell types from the background space, while
    the other penalises the prediction of disease labels, ensuring that disease-specific
    information is isolated in the salient space.'
  Inspired by:
  - DANN
  - DIVA
  - CPA
  - 'scVI '
  Method: scDSA
  Model:
  - NB likelihood
  - Domain-Adversarial NNs
  - VAE
  - Addative Shift
  Publication: https://openreview.net/pdf?id=fkoqMdTlEg
  Published: true
  Task: '[''Non-linear Gene Programmess'', ''Contrastive Disentanglement'']'
  Year: 2023
- Code Availability: https://github.com/insitro/sams-vae
  Description: 'A VAE that encodes input data into background latent variables and
    learns sparse, global (salient) embeddings representing the effects of perturbations.
    These sparse salient embeddings are modeled using a joint relaxed straight-through
    (Beta-)Bernoulli distribution (mask) and a normally distributed latent space.
    This method captures perturbation-specific effects as an additive shift to the
    background representation, analogous to additive shift methods, but it can also
    be thought as a multi-condition extention to the contrastive framework (limited
    to two latent variables (case vs. control), to a more general setup capable of
    learning global embeddings for each perturbation. As in some contrastive methods,
    for perturbation samples, the perturbation (global) embeddings are added to the
    background latent variables to reconstruct the data, while for control samples,
    the perturbation embeddings are effectively set to zero. '
  Inspired by:
  - CPA
  - SVAE/SVAE+
  Method: SAMS-VAE
  Model:
  - VAE
  - NB likelihood
  - Conditional Latent Embeddings
  - Addative Shift
  - Sparse Mechanism Shift
  Publication: https://proceedings.neurips.cc/paper_files/paper/2023/hash/0001ca33ba34ce0351e4612b744b3936-Abstract-Conference.html
  Published: true
  Task: '[''Multi-component Disentanglement'', ''Causal Structure'', ''Seen Perturbation
    Prediction'', ''Combinatorial Effect Prediction'']'
  Year: 2023
- Code Availability: https://github.com/theislab/svaeligr
  Description: A VAE  that combines the sparse mechanism shift from SVAE+ with learning
    a probabilistic pairing between cells and unobserved auxiliary variables. These
    auxilary variables correspond to the observed perturbation labels in SVAE+, but
    here they are learned in a data-driven way (rather than passed as static labels)
    which in turn enables counterfactual context-transfer scenarios.
  Inspired by:
  - SVAE+
  Method: svae-ligr
  Model:
  - VAE
  - NB likelihood
  - Sparse Mechanism Shift
  - Generative/Experience Replay
  Publication: https://openreview.net/pdf?id=8hptqO7sfG
  Published: true
  Task: '[''Seen Perturbation Prediction'', ''Context Transfer'', ''Multi-component
    Disentanglement'']'
  Year: 2024
- Code Availability: https://github.com/Genentech/sVAE
  Description: A VAE that integrates recent advances in sparse mechanism shift modeling
    for single-cell data, inferring a causal structure where perturbation labels identify
    the latent variables affected by each perturbation. The method constructs a graph
    identifying which latent variables are influenced by specific perturbations, promoting
    disentaglement and enabling biological interpretability, such as uncovering perturbations
    affecting shared processes. A key modelling contribution is its probabilistic
    sparsity approach (relaxed straight-through Beta-Bernoulli) on the global sparse
    embeddings (graph),  improving upon its predecessor, SVAE. As such, the latent
    space can be seen as being modelled from a Spike-and-Slab prior.
  Inspired by:
  - SVAE
  Method: sVAE+
  Model:
  - VAE
  - NB likelihood
  - Sparse Mechanism Shift
  Publication: https://proceedings.mlr.press/v213/lopez23a/lopez23a.pdf
  Published: true
  Task: '[''Seen Perturbation Prediction'', ''Multi-component Disentanglement'', ''Causal
    Structure'', ''Non-linear Gene Programmess'']'
  Year: 2023
- Code Availability: '-'
  Description: CausCell integrates causal representation learning with diffusion-based
    generative modeling to generate counterfactual single-cell data. It disentangles
    observed and unobserved concepts using concept-specific adversarial discriminators
    and links the resulting latent representations through a structural causal model
    encoded as a directed acyclic graph. The use of a diffusion model, instead of
    a traditional variational autoencoder, improves sample fidelity and better preserves
    underlying causal relationships during generation.
  Inspired by:
  - AnnealVAE
  - DDPM
  Method: CausCell
  Model:
  - Diffusion
  - Auxilary Classifiers
  Publication: https://www.biorxiv.org/content/biorxiv/early/2024/12/17/2024.12.11.628077.full.pdf
  Published: false
  Task: '[''Multi-component Disentanglement'', ''Causal Structure'', ''Combinatorial
    Effect Prediction'', ''Context Transfer'', ''Seen Perturbations'']'
  Year: 2024
- Code Availability: '-'
  Description: A VAE that combines the contrastiveVI/cVAE architecture with a classifier
    that learns the pairing of perturbation labels to cells. As in ContrastiveVI,
    unperturbed cells are drawn solely from background latent space, while cells classified
    as perturbed are reconstructed from both the background and salient sapces. Additionally,
    Hilbert-Schmidt Independence Criterion (HSIC) is used to disentagle the background
    and salient latent spaces.
  Inspired by:
  - ContrastiveVI
  - scVI
  - cVAE
  Method: SC-VAE
  Model:
  - VAE
  - NB likelihood
  Publication: https://www.biorxiv.org/content/10.1101/2024.01.05.574421v1.full
  Published: true
  Task: '[''Contrastive Disentanglement'', ''Perturbation Responsiveness'']'
  Year: 2024
- Code Availability: https://github.com/Teichlab/celcomen
  Description: "Celcomen (CCE) disentangles intra- and inter-cellular gene regulation\
    \ in spatial transcriptomics data by processing gene expression through two parallel\
    \ interaction functions. One function uses a graph convolution layer (k-hop GNN)\
    \ to learn a gene-gene interaction matrix that captures cross-cell signaling,\
    \ while the other applies a linear layer to model regulation within individual\
    \ cells. During training, Celcomen combines a normalization term\u2014computed\
    \ via a mean field approximation that decomposes the overall likelihood into a\
    \ mean contribution and an interaction contribution - with a similarity measure\
    \ that directly compares each cell\u2019s predicted gene expression (obtained\
    \ via message passing) to its actual expression, thereby driving the model to\
    \ adjust its interaction matrices so that the predictions closely match the observed\
    \ data. Simcomen (SCE) then leverages these fixed, learned matrices to simulate\
    \ spatial counterfactuals (e.g., gene knockouts) for in-silico experiments."
  Inspired by:
  - '-'
  Method: Celcomen
  Model:
  - K-hop Convolution
  - Mean field estimation
  - Spatially-informed
  Publication: https://openreview.net/pdf?id=Tqdsruwyac
  Published: true
  Task: '[''Unsupervised Disentanglement'', ''Feature relationships'']'
  Year: 2025
